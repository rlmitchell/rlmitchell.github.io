{"categories":[{"title":"ansible","uri":"https://rlmitchell.github.io/categories/ansible/"},{"title":"aws","uri":"https://rlmitchell.github.io/categories/aws/"},{"title":"bash","uri":"https://rlmitchell.github.io/categories/bash/"},{"title":"documentation","uri":"https://rlmitchell.github.io/categories/documentation/"},{"title":"markdown","uri":"https://rlmitchell.github.io/categories/markdown/"},{"title":"python","uri":"https://rlmitchell.github.io/categories/python/"}],"posts":[{"content":" Sometimes you need more that a simple list. In Ansible you can use a list of dictionaries to give each item in the list more than one attribute.\n Here is an example playbook that:\n sets the my_list variable to a list of dictionaries use each of the dictionary attributes in a debug statement  - hosts: localhost become: no gather_facts: no vars: my_list: - id: 'id 1' desc: 'desc 1' - id: 'id 2' desc: 'desc 2' tasks: - name: print out dictionary values debug: msg: \u0026quot;{{ item.id }}, {{ item.desc }}\u0026quot; with_items: \u0026quot;{{ my_list }}\u0026quot;   Here\u0026rsquo;s the output of the playbook run:\n$ ansible-playbook using-list-of-dicts.yml PLAY [localhost] **************************************************************************************************** TASK [debug] ******************************************************************************************************** ok: [localhost] =\u0026gt; (item={'id': 'id 1', 'desc': 'desc 1'}) =\u0026gt; { \u0026quot;msg\u0026quot;: \u0026quot;id 1, desc 1\u0026quot; } ok: [localhost] =\u0026gt; (item={'id': 'id 2', 'desc': 'desc 2'}) =\u0026gt; { \u0026quot;msg\u0026quot;: \u0026quot;id 2, desc 2\u0026quot; } PLAY RECAP ********************************************************************************************************** localhost : ok=1 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 $   The example playbook is also on github.\n","id":0,"section":"posts","summary":"Sometimes you need more that a simple list. In Ansible you can use a list of dictionaries to give each item in the list more than one attribute.\n Here is an example playbook that:\n sets the my_list variable to a list of dictionaries use each of the dictionary attributes in a debug statement  - hosts: localhost become: no gather_facts: no vars: my_list: - id: 'id 1' desc: 'desc 1' - id: 'id 2' desc: 'desc 2' tasks: - name: print out dictionary values debug: msg: \u0026quot;{{ item.","tags":["ansible"],"title":"Using a list of dictionaries in Ansible","uri":"https://rlmitchell.github.io/2022/11/2/","year":"2022"},{"content":" Requirements:  All backup objects in S3 start with a common prefix. All backup objects in S3 have a sortable date/timestamp in the object\u0026rsquo;s name. Keep the most current N backups, delete the rest. Use AWSCLI and Bash so it can be added to cron.   Prerequisites The first thing we need to know how to do is create a sorted array. In this case we need to create the array with the output of another command. In the final script we will created the sorted array from the output of the AWSCLI command listing S3 objects.\n$ array=(`echo \u0026quot;b \u0026gt; c \u0026gt; d \u0026gt; a\u0026quot; | sort | tr '\\n' ' '`) $ declare -p array declare -a array=([0]=\u0026quot;a\u0026quot; [1]=\u0026quot;b\u0026quot; [2]=\u0026quot;c\u0026quot; [3]=\u0026quot;d\u0026quot;) $   Next we need to know how to get the number of elements in an array (so we know when to stop deleting objects).\n$ echo ${#array[@]} 4 $   Finally, we need to know how to remvoe the first element of the sorted array.\n$ echo ${array[*]} a b c d $ array=(\u0026quot;${array[@]:1}\u0026quot;) $ echo ${array[*]} b c d $   Building the script Based on our object name requirements, lets list the backup objects we have in our S3 backups bucket sorting them oldest to newest and assign that output to an array.\nOur backup object name prefix is \u0026ldquo;bck.tf-\u0026rdquo; and there are 12 backups in the bucket.\n# clean-tf-backups.sh version dev.1 S3_BUCKET='s3://mybackupsbucket' OBJECT_PREFIX='bck.tf-' array=(`aws s3 ls ${S3_BUCKET} | awk '{print $NF}' | grep \u0026quot;${OBJECT_PREFIX}\u0026quot; | sort`) declare -p array  output:\n$ bash clean-tf-backups.sh declare -a array=([0]=\u0026quot;bck.tf-20221030.185045.tgz\u0026quot; [1]=\u0026quot;bck.tf-20221030.185048.tgz\u0026quot; [2]=\u0026quot;bck.tf-20221030.185051.tgz\u0026quot; [3]=\u0026quot;bck.tf-20221030.185054.tgz\u0026quot; [4]=\u0026quot;bck.tf-20221030.185057.tgz\u0026quot; [5]=\u0026quot;bck.tf-20221030.185100.tgz\u0026quot; [6]=\u0026quot;bck.tf-20221030.185103.tgz\u0026quot; [7]=\u0026quot;bck.tf-20221030.185106.tgz\u0026quot; [8]=\u0026quot;bck.tf-20221030.185109.tgz\u0026quot; [9]=\u0026quot;bck.tf-20221030.185112.tgz\u0026quot; [10]=\u0026quot;bck.tf-20221030.185115.tgz\u0026quot; [11]=\u0026quot;bck.tf-20221030.185118.tgz\u0026quot;) $   We want to keep the last 10 objects, deleting the oldest first. We will echo \u0026ldquo;delete\u0026rdquo; on each of the objects we want to delete to test/verify.\n# clean-tf-backups.sh version: dev.2 S3_BUCKET='s3://mybackupsbucket' OBJECT_PREFIX='bck.tf-' array=(`aws s3 ls ${S3_BUCKET} | awk '{print $NF}' | grep \u0026quot;${OBJECT_PREFIX}\u0026quot;`) declare array while [[ ${#array[@]} -gt 10 ]] do echo \u0026quot;delete ${array[0]}\u0026quot; array=(\u0026quot;${array[@]:1}\u0026quot;) done for obj in ${array[*]} do echo \u0026quot;keep $obj\u0026quot; done  output:\n$ bash clean-tf-backups.sh delete bck.tf-20221030.185045.tgz delete bck.tf-20221030.185048.tgz keep bck.tf-20221030.185051.tgz keep bck.tf-20221030.185054.tgz keep bck.tf-20221030.185057.tgz keep bck.tf-20221030.185100.tgz keep bck.tf-20221030.185103.tgz keep bck.tf-20221030.185106.tgz keep bck.tf-20221030.185109.tgz keep bck.tf-20221030.185112.tgz keep bck.tf-20221030.185115.tgz keep bck.tf-20221030.185118.tgz $   Finally we add the delete command instead of just echoing.\n# clean-tf-backups.sh version: dev.3 S3_BUCKET='s3://mybackupsbucket' OBJECT_PREFIX='bck.tf-' array=(`aws s3 ls ${S3_BUCKET} | awk '{print $NF}' | grep \u0026quot;${OBJECT_PREFIX}\u0026quot;`) declare array while [[ ${#array[@]} -gt 10 ]] do aws s3 rm ${S3_BUCKET}/${array[0]} echo \u0026quot;deleted ${array[0]}\u0026quot; array=(\u0026quot;${array[@]:1}\u0026quot;) done  output:\n$ bash clean-tf-backups.sh delete: s3://mybackupsbucket/bck.tf-20221030.185045.tgz deleted bck.tf-20221030.185045.tgz delete: s3://mybackupsbucket/bck.tf-20221030.185048.tgz deleted bck.tf-20221030.185048.tgz $   Final script and first run # clean-tf-backups.sh S3_BUCKET='s3://mybackupsbucket' OBJECT_PREFIX='bck.tf-' array=(`aws s3 ls ${S3_BUCKET} | awk '{print $NF}' | grep \u0026quot;${OBJECT_PREFIX}\u0026quot;`) declare array while [[ ${#array[@]} -gt 10 ]] do aws s3 rm ${S3_BUCKET}/${array[0]} array=(\u0026quot;${array[@]:1}\u0026quot;) done   Here\u0026rsquo;s a full run: 1) listing all objects, deleteing old ones with the script, and listing the remaining objects.\n$ aws s3 ls s3://mybackupsbucket | awk '{print $NF}' | grep 'bck.tf-' bck.tf-20221030.185045.tgz bck.tf-20221030.185048.tgz bck.tf-20221030.185051.tgz bck.tf-20221030.185054.tgz bck.tf-20221030.185057.tgz bck.tf-20221030.185100.tgz bck.tf-20221030.185103.tgz bck.tf-20221030.185106.tgz bck.tf-20221030.185109.tgz bck.tf-20221030.185112.tgz bck.tf-20221030.185115.tgz bck.tf-20221030.185118.tgz $ bash clean-tf-backups.sh delete: s3://mybackupsbucket/bck.tf-20221030.185045.tgz delete: s3://mybackupsbucket/bck.tf-20221030.185048.tgz $ $ aws s3 ls s3://mybackupsbucket | awk '{print $NF}' | grep 'bck.tf-' bck.tf-20221030.185051.tgz bck.tf-20221030.185054.tgz bck.tf-20221030.185057.tgz bck.tf-20221030.185100.tgz bck.tf-20221030.185103.tgz bck.tf-20221030.185106.tgz bck.tf-20221030.185109.tgz bck.tf-20221030.185112.tgz bck.tf-20221030.185115.tgz bck.tf-20221030.185118.tgz $  ","id":1,"section":"posts","summary":"Requirements:  All backup objects in S3 start with a common prefix. All backup objects in S3 have a sortable date/timestamp in the object\u0026rsquo;s name. Keep the most current N backups, delete the rest. Use AWSCLI and Bash so it can be added to cron.   Prerequisites The first thing we need to know how to do is create a sorted array. In this case we need to create the array with the output of another command.","tags":["aws","s3","bash"],"title":"Removing old backups in S3 with Bash","uri":"https://rlmitchell.github.io/2022/10/2022.10.30-removing-old-backups-in-s3-with-bash/","year":"2022"},{"content":" The first thing we need is our AWSCLI credentials. Having multiple profiles in the AWSCLI credentials file, we need to set our credentials when we instantiate the boto3 client. So we have a simple dict in a file we will import.\n# boto3_credentials.py boto3_credentials = { 'aws_access_key_id':'\u0026lt;YOUR_ACCESS_KEY_ID\u0026gt;', 'aws_secret_access_key':'\u0026lt;YOUR_SECRET_ACCESS_KEY\u0026gt;', 'region_name':'us-east-2' }   Here is our SESEmail class. It takes a credentials dict, a paramaters dict, and a debug boolean to instantiate. To send the email we simple call the object.\n# ses_email.py import boto3 import subprocess from pprint import pprint class SESEmail: def __init__(self, creds, params, debug=False): self.creds = creds self.__dict__.update(params) self.debug = debug self.client = boto3.client( 'ses', region_name = self.creds['region_name'], aws_access_key_id = self.creds['aws_access_key_id'], aws_secret_access_key = self.creds['aws_secret_access_key'] ) def __call__(self): response = self.send_email() if self.debug: pprint(self.__dict__) pprint(response) def send_email(self): response = self.client.send_email( Destination={'ToAddresses': self.to_address_list }, Message={ 'Body': { 'Text': { 'Charset': 'UTF-8', 'Data': self.body }, }, 'Subject': { 'Charset': 'UTF-8', 'Data': self.subject }, }, Source = self.from_address ) return response   Here is a working example with some information redacted (all caps inside \u0026lt;\u0026gt;)\n$ python3 Python 3.8.10 (default, Jun 22 2022, 20:18:18) [GCC 9.4.0] on linux Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; from boto3_credentials import boto3_credentials as creds \u0026gt;\u0026gt;\u0026gt; from ses_email import SESEmail \u0026gt;\u0026gt;\u0026gt; params = { ... 'from_address':'\u0026lt;FROM@TEST.COM\u0026gt;', ... 'to_address_list':['\u0026lt;TO@TEST.COM\u0026gt;'], ... 'subject':'\u0026lt;SOME SUBJECT STRING\u0026gt;', ... 'body':'\u0026lt;SOME BODY STRING\u0026gt;' ... } \u0026gt;\u0026gt;\u0026gt; SESEmail(creds, params, debug=True)() {'body': '\u0026lt;SOME BODY STRING\u0026gt;', 'client': \u0026lt;botocore.client.SES object at 0x7f0a983dec10\u0026gt;, 'creds': {'aws_access_key_id': '\u0026lt;YOUR_ACCESS_KEY_ID\u0026gt;', 'aws_secret_access_key': '\u0026lt;YOUR_SECRET_ACCESS_KEY\u0026gt;', 'region_name': 'us-east-2'}, 'debug': True, 'from_address': '\u0026lt;FROM@TEST.COM\u0026gt;', 'subject': '\u0026lt;SOME SUBJECT STRING\u0026gt;', 'to_address_list': ['\u0026lt;TO@TEST.COM\u0026gt;']} {'MessageId': '010f01842a8bf60a-4ec8b0ad-963e-4add-83d2-2de748d3011a-000000', 'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive', 'content-length': '326', 'content-type': 'text/xml', 'date': 'Sun, 30 Oct 2022 20:18:46 GMT', 'x-amzn-requestid': '088403a4-7754-4c37-87cb-38041f3e5c95'}, 'HTTPStatusCode': 200, 'RequestId': '088403a4-7754-4c37-87cb-38041f3e5c95', 'RetryAttempts': 0}} \u0026gt;\u0026gt;\u0026gt; quit() $  ","id":2,"section":"posts","summary":"The first thing we need is our AWSCLI credentials. Having multiple profiles in the AWSCLI credentials file, we need to set our credentials when we instantiate the boto3 client. So we have a simple dict in a file we will import.\n# boto3_credentials.py boto3_credentials = { 'aws_access_key_id':'\u0026lt;YOUR_ACCESS_KEY_ID\u0026gt;', 'aws_secret_access_key':'\u0026lt;YOUR_SECRET_ACCESS_KEY\u0026gt;', 'region_name':'us-east-2' }   Here is our SESEmail class. It takes a credentials dict, a paramaters dict, and a debug boolean to instantiate.","tags":["aws","ses","python"],"title":"Sending email with AWS Simple Email Service (SES) and Python","uri":"https://rlmitchell.github.io/2022/10/2022.10.30-python-send-email-with-aws-ses/","year":"2022"},{"content":" This is super simple but, I mention it because I\u0026rsquo;ve been wanting a way to put comments into some of my markdown documents. I came across this solution today and it seems to work well at least in Hugo.\nUsing link labels to achieve it: [comment]: \u0026lt;\u0026gt; (this is how to make a md comment)\nreference: stackoverflow post\n","id":3,"section":"posts","summary":"This is super simple but, I mention it because I\u0026rsquo;ve been wanting a way to put comments into some of my markdown documents. I came across this solution today and it seems to work well at least in Hugo.\nUsing link labels to achieve it: [comment]: \u0026lt;\u0026gt; (this is how to make a md comment)\nreference: stackoverflow post","tags":["markdown"],"title":"How to write comments in markdown","uri":"https://rlmitchell.github.io/2022/10/2022.10.29-markdown-comments/","year":"2022"}],"tags":[{"title":"ansible","uri":"https://rlmitchell.github.io/tags/ansible/"},{"title":"aws","uri":"https://rlmitchell.github.io/tags/aws/"},{"title":"bash","uri":"https://rlmitchell.github.io/tags/bash/"},{"title":"markdown","uri":"https://rlmitchell.github.io/tags/markdown/"},{"title":"python","uri":"https://rlmitchell.github.io/tags/python/"},{"title":"s3","uri":"https://rlmitchell.github.io/tags/s3/"},{"title":"ses","uri":"https://rlmitchell.github.io/tags/ses/"}]}